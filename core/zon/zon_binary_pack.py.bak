"""
ZON Binary Pack/Unpack Module
Handles both dictionary and array root structures
"""

import struct
from typing import Any, Dict, List, Tuple, Union
import json


# ZON Binary Format Constants
ZONB_MAGIC = b'ZONB'
ZONB_VERSION = 1

# Type bytes
TYPE_NULL = 0x00
TYPE_BOOL = 0x01
TYPE_INT = 0x02
TYPE_FLOAT = 0x03
TYPE_STRING = 0x04
TYPE_ARRAY = 0x05
TYPE_DICT = 0x06
TYPE_ROOT_ARRAY = 0x07  # Special marker for root-level arrays

# Field ID mappings - COMPLETE VERSION
FIELD_IDS = {
    "type": 0x01,
    "id": 0x02,
    "description": 0x03,
    "flags": 0x04,
    "name": 0x05,
    "mood": 0x06,
    "action": 0x07,
    "environment": 0x08,
    "lighting": 0x09,
    "ambience": 0x0A,
    "overlays": 0x0B,
    "npc_state": 0x0C,
    "narrative_pulse": 0x0D,
    "speaker": 0x0E,
    "emotion": 0x0F,
    "line": 0x10,
    "leads_to": 0x11,
    "trigger": 0x12,
    "op": 0x13,
    "left": 0x14,
    "right": 0x15,
    # Container/Item fields
    "container": 0x16,
    "contents": 0x17,
    "item": 0x18,
    "quantity": 0x19,
    # Additional common fields
    "npc": 0x1A,
    "room": 0x1B,
    "rule": 0x1C,
    "exits": 0x1D,
    "objects": 0x1E,
    "level": 0x1F,
    "health": 0x20,
    "hostile": 0x21,
    "dialogue": 0x22,
    "greeting": 0x23,
    "damage": 0x24,
    "weight": 0x25,
}

REVERSE_FIELD_IDS = {v: k for k, v in FIELD_IDS.items()}


def write_varint(value: int) -> bytes:
    """Write a variable-length integer"""
    result = []
    while value > 0x7F:
        result.append((value & 0x7F) | 0x80)
        value >>= 7
    result.append(value & 0x7F)
    return bytes(result)


def read_varint(data: bytes, ptr: int) -> Tuple[int, int]:
    """Read a variable-length integer"""
    value = 0
    shift = 0
    while ptr < len(data):
        byte = data[ptr]
        ptr += 1
        value |= (byte & 0x7F) << shift
        if (byte & 0x80) == 0:
            break
        shift += 7
    return value, ptr


def write_value(value: Any) -> bytes:
    """Encode a value to binary format"""
    if value is None:
        return bytes([TYPE_NULL])
    
    elif isinstance(value, bool):
        return bytes([TYPE_BOOL, 1 if value else 0])
    
    elif isinstance(value, int):
        # Use varint encoding for integers
        return bytes([TYPE_INT]) + write_varint(value)
    
    elif isinstance(value, float):
        return bytes([TYPE_FLOAT]) + struct.pack('<f', value)
    
    elif isinstance(value, str):
        encoded = value.encode('utf-8')
        return bytes([TYPE_STRING]) + write_varint(len(encoded)) + encoded
    
    elif isinstance(value, list):
        result = bytes([TYPE_ARRAY]) + write_varint(len(value))
        for item in value:
            result += write_value(item)
        return result
    
    elif isinstance(value, dict):
        result = bytes([TYPE_DICT]) + write_varint(len(value))
        for key, val in value.items():
            # Try to map field name to ID
            field_id = FIELD_IDS.get(key)
            if field_id is None:
                # Try extracting number from field_N pattern
                if key.startswith("field_"):
                    try:
                        field_id = int(key[6:])
                    except ValueError:
                        field_id = hash(key) & 0xFF  # Fallback
                else:
                    field_id = hash(key) & 0xFF  # Use hash for unknown fields
            
            result += write_varint(field_id) + write_value(val)
        return result
    
    else:
        raise TypeError(f"Cannot encode type {type(value)}")


def read_value(data: bytes, ptr: int) -> Tuple[Any, int]:
    """Read a value from binary data"""
    if ptr >= len(data):
        raise ValueError(f"Pointer {ptr} exceeds data length {len(data)}")
    
    type_byte = data[ptr]
    ptr += 1
    
    if type_byte == TYPE_NULL:
        return None, ptr
    
    elif type_byte == TYPE_BOOL:
        value = bool(data[ptr])
        return value, ptr + 1
    
    elif type_byte == TYPE_INT:
        return read_varint(data, ptr)
    
    elif type_byte == TYPE_FLOAT:
        value = struct.unpack('<f', data[ptr:ptr+4])[0]
        return value, ptr + 4
    
    elif type_byte == TYPE_STRING:
        str_len, ptr = read_varint(data, ptr)
        value = data[ptr:ptr+str_len].decode('utf-8')
        return value, ptr + str_len
    
    elif type_byte == TYPE_ARRAY:
        arr_len, ptr = read_varint(data, ptr)
        arr = []
        for _ in range(arr_len):
            elem, ptr = read_value(data, ptr)
            arr.append(elem)
        return arr, ptr
    
    elif type_byte == TYPE_DICT:
        dict_len, ptr = read_varint(data, ptr)
        result = {}
        for _ in range(dict_len):
            field_id, ptr = read_varint(data, ptr)
            field_name = REVERSE_FIELD_IDS.get(field_id, f"field_{field_id}")
            value, ptr = read_value(data, ptr)
            result[field_name] = value
        return result, ptr
    
    elif type_byte == TYPE_ROOT_ARRAY:
        # Special handling for root arrays
        arr_len, ptr = read_varint(data, ptr)
        arr = []
        for _ in range(arr_len):
            elem, ptr = read_value(data, ptr)
            arr.append(elem)
        return arr, ptr
    
    else:
        raise ValueError(f"Unknown type byte: 0x{type_byte:02x} at position {ptr-1}")


def pack_zonj(data: Union[Dict, List], preserve_root_array: bool = True) -> bytes:
    """
    Pack ZONJ (JSON) data to binary ZONB format
    
    Args:
        data: Dictionary or List to pack
        preserve_root_array: If True, root arrays are marked specially
        
    Returns:
        Binary packed ZONB data
    """
    result = ZONB_MAGIC + bytes([ZONB_VERSION])
    
    # Handle root-level arrays specially
    if preserve_root_array and isinstance(data, list):
        # Use special root array type
        result += bytes([TYPE_ROOT_ARRAY]) + write_varint(len(data))
        for item in data:
            result += write_value(item)
    else:
        # Standard value encoding
        result += write_value(data)
    
    return result


def unpack_zonb(binary_data: bytes, auto_unwrap: bool = True) -> Union[Dict, List]:
    """
    Unpack binary ZONB data back to ZONJ (JSON) structure
    
    Args:
        binary_data: Binary packed ZONB data
        auto_unwrap: If True, automatically unwrap single-field dictionaries containing arrays
        
    Returns:
        Dictionary or List representation of unpacked data
    """
    # Verify magic header
    if len(binary_data) < 4 or binary_data[:4] != ZONB_MAGIC:
        raise ValueError("Invalid ZONB magic header")
    
    ptr = 4
    
    # Read version
    if ptr < len(binary_data):
        version = binary_data[ptr]
        if version != ZONB_VERSION:
            print(f"Warning: Version mismatch. Expected {ZONB_VERSION}, got {version}")
        ptr += 1
    
    # Check for root array marker
    if ptr < len(binary_data) and binary_data[ptr] == TYPE_ROOT_ARRAY:
        ptr += 1
        arr_len, ptr = read_varint(binary_data, ptr)
        arr = []
        for _ in range(arr_len):
            elem, ptr = read_value(binary_data, ptr)
            arr.append(elem)
        return arr
    
    # Read the root value normally
    root_value, ptr = read_value(binary_data, ptr)
    
    # Auto-unwrap wrapped arrays if enabled
    if auto_unwrap and isinstance(root_value, dict):
        keys = list(root_value.keys())
        if len(keys) == 1 and keys[0].startswith("field_") and isinstance(root_value[keys[0]], list):
            return root_value[keys[0]]
    
    return root_value


# Convenience functions for file I/O
def pack_file(input_path: str, output_path: str, preserve_root_array: bool = True):
    """Pack a JSON file to ZONB binary format"""
    with open(input_path, 'r') as f:
        data = json.load(f)
    
    binary_data = pack_zonj(data, preserve_root_array)
    
    with open(output_path, 'wb') as f:
        f.write(binary_data)
    
    return len(binary_data)


def unpack_file(input_path: str, output_path: str, auto_unwrap: bool = True, pretty: bool = True):
    """Unpack a ZONB binary file to JSON"""
    with open(input_path, 'rb') as f:
        binary_data = f.read()
    
    data = unpack_zonb(binary_data, auto_unwrap)
    
    with open(output_path, 'w') as f:
        if pretty:
            json.dump(data, f, indent=2)
        else:
            json.dump(data, f)
    
    return data

# ========================================================
# BACKWARDS-COMPATIBILITY SHIM â€” DO NOT REMOVE
# Some legacy modules expect these function names.
# ========================================================
def pack_to_zonb(data, preserve_root_array: bool = True):
    return pack_zonj(data, preserve_root_array=preserve_root_array)

def unpack_from_zonb(binary_data: bytes, auto_unwrap: bool = True):
    return unpack_zonb(binary_data, auto_unwrap=auto_unwrap)

# Optional: expose in __all__ if module uses it
if '__all__' in globals():
    __all__.extend(["pack_to_zonb", "unpack_from_zonb"])
else:
    __all__ = ["pack_to_zonb", "unpack_from_zonb"]
# Backwards-compatibility aliases (for older code/tests)
# ----------------------------------------------------
def pack_to_zonb(data, preserve_root_array: bool = True):
    """Alias for pack_zonj (old name used in GUI/tests)"""
    return pack_zonj(data, preserve_root_array=preserve_root_array)

def unpack_from_zonb(binary_data: bytes, auto_unwrap: bool = True):
    """Alias for unpack_zonb (old name used in GUI/tests)"""
    return unpack_zonb(binary_data, auto_unwrap=auto_unwrap)

# Expose in __all__ if defined
if '__all__' in globals():
    __all__ += ['pack_to_zonb', 'unpack_from_zonb']
